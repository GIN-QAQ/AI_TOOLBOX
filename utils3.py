
# ğŸ’¬ å…‹éš†ChatGPT

from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain_openai import ChatOpenAI


def get_chat_response(prompt, memory, openai_api_key):
    model = ChatOpenAI(model="gpt-3.5-turbo",
                       openai_api_key=openai_api_key,
                       base_url="https://api.aigc369.com/v1")
    chain = ConversationChain(llm=model, memory=memory)

    response = chain.invoke({"input": prompt})
    return response["response"]


# memory = ConversationBufferMemory(return_message=True)
# print(get_chat_response("ç‰›é¡¿æå‡ºè¿‡å“ªäº›çŸ¥åçš„å®šå¾‹ï¼Ÿ", memory, os.getenv("OPENAI_API_KEY")))
# print(get_chat_response("æˆ‘ä¸Šä¸€ä¸ªé—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ", memory, os.getenv("OPENAI_API_KEY")))